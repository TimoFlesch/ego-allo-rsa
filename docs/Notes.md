
1.	I think training on the same directions + noise would give a similar outcome to training on random directions. The rational for this was that if we only trained on the small set of trials in the task that the network would learn a strategy that would be very idiosyncratic and not generalise. What we did , to make plots like in the paper was to train on random configurations but to test on the same set that we used in the task.
2.	The stimulus presentation was not static. In the task we first present the start position and then after a delay present the target and then after another delay present the “go” cue. In our initial network model we had 11 frames. On the first frame we presented the start, which stayed on for the whole 11 frames. Then after 2-4 frames we would present the target **only for one frame**. Then after a 11 frames past we would change the training label from the start position (in the relevant coordinates) to the target position (in the relative coordinates).
For the self-world and self-self networks the start coordinates were always 0,0. For the world-self and world-world coordinates, the self coordinates were the (x,y) position of the start relative to some fixed anchor. We tested using the top-right corner as 0,0 (so all coordinates were positive and the centre was 32,32) and we also tested having 0,0 as the centre and having positive and negative targets. It didn’t make any difference to training or the rsa.

Hopefully this helps and sorry again for the long delay.
